{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13722850,"sourceType":"datasetVersion","datasetId":8730799}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T18:35:12.082189Z","iopub.execute_input":"2025-11-13T18:35:12.082534Z","iopub.status.idle":"2025-11-13T18:35:12.460273Z","shell.execute_reply.started":"2025-11-13T18:35:12.082510Z","shell.execute_reply":"2025-11-13T18:35:12.459410Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ml-data/Corpus/ML_corpus.txt\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ---------------------------------------------------------\n# FIX ENVIRONMENT BEFORE ANYTHING ELSE\n# ---------------------------------------------------------\n\n# 1. Fix protobuf issue (transformers bug on Kaggle)\n!pip install protobuf==4.25.3 --quiet --force-reinstall\n\n# 2. Remove TensorFlow to avoid cuDNN/cuFFT/cuBLAS spam + protobuf conflict\n!pip uninstall -y tensorflow tensorflow-cpu tensorflow-gpu keras\n\n# 3. Fix pyarrow to correct version (Kaggle uses pyarrow-19.x)\n!pip install pyarrow==19.0.0 --quiet --force-reinstall --no-deps\n\n# 4. Install ONLY the necessary libraries WITHOUT upgrading pyarrow again\n!pip install transformers==4.53.3 datasets==2.19.1 accelerate tokenizers==0.21.2 --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom tokenizers import ByteLevelBPETokenizer\nfrom transformers import GPT2TokenizerFast\n\nCORPUS_PATH = \"/kaggle/input/ml-data/Corpus/ML_corpus.txt\"\nTOKENIZER_DIR = \"./custom_tokenizer\"\n\nprint(\"Corpus exists:\", os.path.exists(CORPUS_PATH))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:47:54.373552Z","iopub.execute_input":"2025-11-14T06:47:54.373826Z","iopub.status.idle":"2025-11-14T06:48:00.456406Z","shell.execute_reply.started":"2025-11-14T06:47:54.373803Z","shell.execute_reply":"2025-11-14T06:48:00.455533Z"}},"outputs":[{"name":"stdout","text":"Corpus exists: True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"if not os.path.exists(TOKENIZER_DIR):\n    os.makedirs(TOKENIZER_DIR)\n\nprint(\"Training custom tokenizer...\")\n\ntokenizer_raw = ByteLevelBPETokenizer()\n\ntokenizer_raw.train(\n    files=CORPUS_PATH,\n    vocab_size=24000,\n    min_frequency=2,\n    special_tokens=[\"<|pad|>\",\"<|bos|>\",\"<|eos|>\",\"<|unk|>\"]\n)\n\ntokenizer_raw.save_model(TOKENIZER_DIR)\n\ntokenizer = GPT2TokenizerFast.from_pretrained(\n    TOKENIZER_DIR,\n    pad_token=\"<|pad|>\",\n    bos_token=\"<|bos|>\",\n    eos_token=\"<|eos|>\",\n    unk_token=\"<|unk|>\"\n)\n\nprint(\"Custom tokenizer vocab size:\", tokenizer.vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:51:04.559187Z","iopub.execute_input":"2025-11-14T06:51:04.560014Z","iopub.status.idle":"2025-11-14T06:53:12.247338Z","shell.execute_reply.started":"2025-11-14T06:51:04.559987Z","shell.execute_reply":"2025-11-14T06:53:12.246396Z"}},"outputs":[{"name":"stdout","text":"Training custom tokenizer...\n\n\n\nCustom tokenizer vocab size: 24000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import GPT2Config, GPT2LMHeadModel\n\nCONTEXT_SIZE = 384\n\nconfig = GPT2Config(\n    vocab_size=tokenizer.vocab_size,\n    n_positions=384,\n    n_ctx=384,\n    n_embd=384,\n    n_layer=10,\n    n_head=6\n)\n\nmodel = GPT2LMHeadModel(config)\nmodel.resize_token_embeddings(tokenizer.vocab_size)\n\nprint(\"Model parameters (M):\", round(sum(p.numel() for p in model.parameters())/1e6, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:18:20.387734Z","iopub.execute_input":"2025-11-14T07:18:20.388063Z","iopub.status.idle":"2025-11-14T07:18:21.064519Z","shell.execute_reply.started":"2025-11-14T07:18:20.388038Z","shell.execute_reply":"2025-11-14T07:18:21.063496Z"}},"outputs":[{"name":"stdout","text":"Model parameters (M): 27.109\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"text\", data_files={\"train\": CORPUS_PATH})\ndataset = dataset[\"train\"].train_test_split(test_size=0.01, seed=42)\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        max_length=CONTEXT_SIZE,\n        return_overflowing_tokens=False,\n    )\n\ntokenized = dataset.map(\n    tokenize,\n    batched=True,\n    num_proc=1,\n    remove_columns=[\"text\"]\n)\n\ntokenized = tokenized.filter(lambda x: len(x[\"input_ids\"]) > 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:53:34.572481Z","iopub.execute_input":"2025-11-14T06:53:34.573109Z","iopub.status.idle":"2025-11-14T07:05:02.703689Z","shell.execute_reply.started":"2025-11-14T06:53:34.573084Z","shell.execute_reply":"2025-11-14T07:05:02.702982Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d32f45bd3446d781d531bb48be73c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=1):   0%|          | 0/1756453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6fc0b1b6a8744f487a00cc2f3c801df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=1):   0%|          | 0/17742 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cd405c9ad1e4b4b9a07f2adff24e465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1756453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84f3284a665e4f9b9c845bdac2889429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/17742 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc27013468cb4427840b9de6c5885cd2"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\n\ntrain_max = np.max([np.max(x) for x in tokenized[\"train\"][\"input_ids\"]])\ntest_max = np.max([np.max(x) for x in tokenized[\"test\"][\"input_ids\"]])\n\nprint(\"vocab size:\", tokenizer.vocab_size)\nprint(\"max train id:\", train_max)\nprint(\"max test id:\", test_max)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:05:02.705294Z","iopub.execute_input":"2025-11-14T07:05:02.705881Z","iopub.status.idle":"2025-11-14T07:07:58.237524Z","shell.execute_reply.started":"2025-11-14T07:05:02.705860Z","shell.execute_reply":"2025-11-14T07:07:58.236466Z"}},"outputs":[{"name":"stdout","text":"vocab size: 24000\nmax train id: 23999\nmax test id: 23999\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:18:34.162467Z","iopub.execute_input":"2025-11-14T07:18:34.163241Z","iopub.status.idle":"2025-11-14T07:18:34.167073Z","shell.execute_reply.started":"2025-11-14T07:18:34.163215Z","shell.execute_reply":"2025-11-14T07:18:34.166143Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./ml_gpt_model\",\n    overwrite_output_dir=True,\n    num_train_epochs=2,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=2,\n    learning_rate=5e-4,\n    warmup_steps=200,\n    weight_decay=0.1,\n\n    logging_steps=500,\n\n    eval_strategy=\"steps\",\n    eval_steps=10000,\n    per_device_eval_batch_size=16,\n    prediction_loss_only=True,\n\n    save_strategy=\"no\",\n    bf16=True,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:18:40.403127Z","iopub.execute_input":"2025-11-14T07:18:40.403723Z","iopub.status.idle":"2025-11-14T07:18:40.437937Z","shell.execute_reply.started":"2025-11-14T07:18:40.403694Z","shell.execute_reply":"2025-11-14T07:18:40.437117Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized[\"train\"],\n    eval_dataset=tokenized[\"test\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:18:46.254319Z","iopub.execute_input":"2025-11-14T07:18:46.254806Z","iopub.status.idle":"2025-11-14T07:18:46.311952Z","shell.execute_reply.started":"2025-11-14T07:18:46.254780Z","shell.execute_reply":"2025-11-14T07:18:46.311111Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T07:18:48.450514Z","iopub.execute_input":"2025-11-14T07:18:48.451135Z","iopub.status.idle":"2025-11-14T16:43:25.290740Z","shell.execute_reply.started":"2025-11-14T07:18:48.451110Z","shell.execute_reply":"2025-11-14T16:43:25.290046Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='37810' max='37810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [37810/37810 9:24:35, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10000</td>\n      <td>1.841600</td>\n      <td>3.623037</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>1.721100</td>\n      <td>3.401062</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>1.652700</td>\n      <td>3.270133</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=37810, training_loss=1.796148332960547, metrics={'train_runtime': 33876.3197, 'train_samples_per_second': 71.428, 'train_steps_per_second': 1.116, 'total_flos': 8.667233317239091e+16, 'train_loss': 1.796148332960547, 'epoch': 2.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"trainer.save_model(\"./ml_gpt_model\")\ntokenizer.save_pretrained(\"./ml_gpt_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:49:46.495545Z","iopub.execute_input":"2025-11-14T16:49:46.496333Z","iopub.status.idle":"2025-11-14T16:49:46.799519Z","shell.execute_reply.started":"2025-11-14T16:49:46.496307Z","shell.execute_reply":"2025-11-14T16:49:46.798912Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('./ml_gpt_model/tokenizer_config.json',\n './ml_gpt_model/special_tokens_map.json',\n './ml_gpt_model/vocab.json',\n './ml_gpt_model/merges.txt',\n './ml_gpt_model/added_tokens.json',\n './ml_gpt_model/tokenizer.json')"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"!zip -r model.zip ./ml_gpt_model\nfrom IPython.display import FileLink\nFileLink('model.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T16:49:50.000060Z","iopub.execute_input":"2025-11-14T16:49:50.000993Z","iopub.status.idle":"2025-11-14T16:49:56.325648Z","shell.execute_reply.started":"2025-11-14T16:49:50.000962Z","shell.execute_reply":"2025-11-14T16:49:56.324816Z"}},"outputs":[{"name":"stdout","text":"  adding: ml_gpt_model/ (stored 0%)\n  adding: ml_gpt_model/special_tokens_map.json (deflated 78%)\n  adding: ml_gpt_model/generation_config.json (deflated 24%)\n  adding: ml_gpt_model/tokenizer.json (deflated 82%)\n  adding: ml_gpt_model/training_args.bin (deflated 52%)\n  adding: ml_gpt_model/model.safetensors (deflated 7%)\n  adding: ml_gpt_model/tokenizer_config.json (deflated 73%)\n  adding: ml_gpt_model/vocab.json (deflated 60%)\n  adding: ml_gpt_model/config.json (deflated 51%)\n  adding: ml_gpt_model/merges.txt (deflated 57%)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model.zip","text/html":"<a href='model.zip' target='_blank'>model.zip</a><br>"},"metadata":{}}],"execution_count":17}]}