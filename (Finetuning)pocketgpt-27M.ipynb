{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13735645,"sourceType":"datasetVersion","datasetId":8739580}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:03:20.873425Z","iopub.execute_input":"2025-11-14T19:03:20.873700Z","iopub.status.idle":"2025-11-14T19:03:21.197852Z","shell.execute_reply.started":"2025-11-14T19:03:20.873678Z","shell.execute_reply":"2025-11-14T19:03:21.197069Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/conversational-data/convo/conversational_dataset.txt\n/kaggle/input/conversational-data/convo/pocketGPT-27M/config.json\n/kaggle/input/conversational-data/convo/pocketGPT-27M/merges.txt\n/kaggle/input/conversational-data/convo/pocketGPT-27M/training_args.bin\n/kaggle/input/conversational-data/convo/pocketGPT-27M/tokenizer.json\n/kaggle/input/conversational-data/convo/pocketGPT-27M/vocab.json\n/kaggle/input/conversational-data/convo/pocketGPT-27M/tokenizer_config.json\n/kaggle/input/conversational-data/convo/pocketGPT-27M/model.safetensors\n/kaggle/input/conversational-data/convo/pocketGPT-27M/special_tokens_map.json\n/kaggle/input/conversational-data/convo/pocketGPT-27M/generation_config.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ---------------------------------------------------------\n# FIX ENVIRONMENT BEFORE ANYTHING ELSE\n# ---------------------------------------------------------\n\n# 1. Fix protobuf issue (transformers bug on Kaggle)\n!pip install protobuf==4.25.3 --quiet --force-reinstall\n\n# 2. Remove TensorFlow to avoid cuDNN/cuFFT/cuBLAS spam + protobuf conflict\n!pip uninstall -y tensorflow tensorflow-cpu tensorflow-gpu keras\n\n# 3. Fix pyarrow to correct version (Kaggle uses pyarrow-19.x)\n!pip install pyarrow==19.0.0 --quiet --force-reinstall --no-deps\n\n# 4. Install ONLY the necessary libraries WITHOUT upgrading pyarrow again\n!pip install transformers==4.53.3 datasets==2.19.1 accelerate tokenizers==0.21.2 --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n\nMODEL_DIR = \"/kaggle/input/conversational-data/convo/pocketGPT-27M\"  \n\ntokenizer = GPT2TokenizerFast.from_pretrained(MODEL_DIR)\n\ntokenizer.pad_token = \"<|pad|>\"\ntokenizer.bos_token = \"<|bos|>\"\ntokenizer.eos_token = \"<|eos|>\"\ntokenizer.unk_token = \"<|unk|>\"\n\nmodel = GPT2LMHeadModel.from_pretrained(MODEL_DIR)\nmodel.resize_token_embeddings(len(tokenizer))\n\nprint(\"Tokenizer size:\", tokenizer.vocab_size)\nprint(\"Model loaded.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:03:25.184439Z","iopub.execute_input":"2025-11-14T19:03:25.185217Z","iopub.status.idle":"2025-11-14T19:03:38.623846Z","shell.execute_reply.started":"2025-11-14T19:03:25.185192Z","shell.execute_reply":"2025-11-14T19:03:38.623154Z"}},"outputs":[{"name":"stdout","text":"Tokenizer size: 24000\nModel loaded.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\nDATA_PATH = \"/kaggle/input/conversational-data/convo/conversational_dataset.txt\"\n\ndataset = load_dataset(\"text\", data_files={\"train\": DATA_PATH})\ndataset = dataset[\"train\"].train_test_split(test_size=0.02, seed=42)\n\nprint(dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:03:42.027715Z","iopub.execute_input":"2025-11-14T19:03:42.028586Z","iopub.status.idle":"2025-11-14T19:03:43.765151Z","shell.execute_reply.started":"2025-11-14T19:03:42.028559Z","shell.execute_reply":"2025-11-14T19:03:43.764541Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b4f185e26954efab52d5ad155fb8260"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 171321\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 3497\n    })\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"CONTEXT_WINDOW = 384\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"text\"],\n        max_length=CONTEXT_WINDOW,\n        truncation=True,\n        padding=\"max_length\"\n    )\n\ntokenized = dataset.map(\n    tokenize,\n    batched=True,\n    remove_columns=[\"text\"]\n)\n\nprint(tokenized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:03:46.264989Z","iopub.execute_input":"2025-11-14T19:03:46.265828Z","iopub.status.idle":"2025-11-14T19:04:16.989693Z","shell.execute_reply.started":"2025-11-14T19:03:46.265801Z","shell.execute_reply":"2025-11-14T19:04:16.988812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/171321 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9b83cb2c1e41469e51ade670465e73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3497 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c0a0be7c9604fb6b5ca0edffc7fdd15"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 171321\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 3497\n    })\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:04:25.088318Z","iopub.execute_input":"2025-11-14T19:04:25.088857Z","iopub.status.idle":"2025-11-14T19:04:25.092557Z","shell.execute_reply.started":"2025-11-14T19:04:25.088832Z","shell.execute_reply":"2025-11-14T19:04:25.091810Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./QNA_pocketGPT_27M\",\n    overwrite_output_dir=True,\n\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=1,\n\n    learning_rate=1e-4,\n    warmup_steps=200,\n    weight_decay=0.1,\n\n    logging_steps=200,\n\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    save_strategy=\"epoch\",\n\n    fp16=True,\n    bf16=False,\n\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:12:20.259217Z","iopub.execute_input":"2025-11-14T19:12:20.259914Z","iopub.status.idle":"2025-11-14T19:12:20.300400Z","shell.execute_reply.started":"2025-11-14T19:12:20.259887Z","shell.execute_reply":"2025-11-14T19:12:20.299785Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized[\"train\"],\n    eval_dataset=tokenized[\"test\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:12:23.134555Z","iopub.execute_input":"2025-11-14T19:12:23.134849Z","iopub.status.idle":"2025-11-14T19:12:23.150395Z","shell.execute_reply.started":"2025-11-14T19:12:23.134830Z","shell.execute_reply":"2025-11-14T19:12:23.149761Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:12:25.716635Z","iopub.execute_input":"2025-11-14T19:12:25.717388Z","iopub.status.idle":"2025-11-14T21:32:56.322022Z","shell.execute_reply.started":"2025-11-14T19:12:25.717362Z","shell.execute_reply":"2025-11-14T21:32:56.321404Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16062' max='16062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16062/16062 2:20:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.811400</td>\n      <td>3.674355</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.735600</td>\n      <td>3.526501</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.715600</td>\n      <td>3.445900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.639400</td>\n      <td>3.382370</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.620400</td>\n      <td>3.326509</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.626000</td>\n      <td>3.279655</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.561800</td>\n      <td>3.246620</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.576600</td>\n      <td>3.211287</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.620100</td>\n      <td>3.184350</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.601100</td>\n      <td>3.158545</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.535300</td>\n      <td>3.132509</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.486000</td>\n      <td>3.118061</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.510200</td>\n      <td>3.095500</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.496100</td>\n      <td>3.078604</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.457100</td>\n      <td>3.065130</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.480300</td>\n      <td>3.044423</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.416900</td>\n      <td>3.038350</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.445700</td>\n      <td>3.021653</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.419500</td>\n      <td>3.006731</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.432500</td>\n      <td>2.994688</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>1.437500</td>\n      <td>2.986185</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>1.428800</td>\n      <td>2.979231</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>1.395800</td>\n      <td>2.972527</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>1.437700</td>\n      <td>2.963953</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>1.378000</td>\n      <td>2.956430</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>1.384600</td>\n      <td>2.950437</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>1.361600</td>\n      <td>2.943571</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>1.370100</td>\n      <td>2.937927</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>1.358200</td>\n      <td>2.934673</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>1.387100</td>\n      <td>2.929659</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>1.385400</td>\n      <td>2.926755</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>1.377000</td>\n      <td>2.925359</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16062, training_loss=1.4993742799242353, metrics={'train_runtime': 8430.2626, 'train_samples_per_second': 60.966, 'train_steps_per_second': 1.905, 'total_flos': 2.1013593135906816e+16, 'train_loss': 1.4993742799242353, 'epoch': 3.0})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:36:27.984849Z","iopub.execute_input":"2025-11-14T21:36:27.985191Z","iopub.status.idle":"2025-11-14T21:36:27.991909Z","shell.execute_reply.started":"2025-11-14T21:36:27.985169Z","shell.execute_reply":"2025-11-14T21:36:27.991305Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(24000, 384)\n    (wpe): Embedding(384, 384)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-9): 10 x GPT2Block(\n        (ln_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=1152, nx=384)\n          (c_proj): Conv1D(nf=384, nx=384)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=1536, nx=384)\n          (c_proj): Conv1D(nf=384, nx=1536)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=384, out_features=24000, bias=False)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import torch\ndef ask(prompt):\n    formatted = f\"<|bos|>Instruction: {prompt}\\nResponse:\"\n    \n    inputs = tokenizer.encode(formatted, return_tensors=\"pt\")\n    inputs = inputs.to(model.device) \n\n    with torch.no_grad():\n        outputs = model.generate(\n            inputs,\n            max_length=384,\n            do_sample=True,\n            top_p=0.9,\n            temperature=0.8,\n            eos_token_id=tokenizer.eos_token_id,\n            pad_token_id=tokenizer.pad_token_id\n        )\n\n    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T22:09:02.603846Z","iopub.execute_input":"2025-11-14T22:09:02.604511Z","iopub.status.idle":"2025-11-14T22:09:02.609551Z","shell.execute_reply.started":"2025-11-14T22:09:02.604484Z","shell.execute_reply":"2025-11-14T22:09:02.608611Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"ask(\"Explain model overfitting\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T22:09:06.828765Z","iopub.execute_input":"2025-11-14T22:09:06.829064Z","iopub.status.idle":"2025-11-14T22:09:07.092789Z","shell.execute_reply.started":"2025-11-14T22:09:06.829042Z","shell.execute_reply":"2025-11-14T22:09:07.092074Z"}},"outputs":[{"name":"stdout","text":"Instruction: Explain model overfitting\nResponse: “The only way to reduce the number of mistakes in the code is to use a function to fix it.”\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"ask(\"What is a GPT?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T22:09:12.893804Z","iopub.execute_input":"2025-11-14T22:09:12.894536Z","iopub.status.idle":"2025-11-14T22:09:13.161103Z","shell.execute_reply.started":"2025-11-14T22:09:12.894512Z","shell.execute_reply":"2025-11-14T22:09:13.160259Z"}},"outputs":[{"name":"stdout","text":"Instruction: What is a GPT?\nResponse: The two most powerful models of computer science are GPT and other models. GPT is a transformer-based model for understanding and solving language problems.\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"ask(\"what is Linear Regression Algorith in Machine Learning?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T22:10:15.283477Z","iopub.execute_input":"2025-11-14T22:10:15.284054Z","iopub.status.idle":"2025-11-14T22:10:15.671848Z","shell.execute_reply.started":"2025-11-14T22:10:15.284026Z","shell.execute_reply":"2025-11-14T22:10:15.670992Z"}},"outputs":[{"name":"stdout","text":"Instruction: what is Linear Regression Algorith in Machine Learning?\nResponse: A supervised machine learning algorithm that can be used to predict the output of a given data set. Output is the best predictions of the data set. Output can be classified as either a classification problem or a regression problem.\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"ask(\"what is an Artificial Neural Network?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T22:09:24.653533Z","iopub.execute_input":"2025-11-14T22:09:24.653827Z","iopub.status.idle":"2025-11-14T22:09:25.476793Z","shell.execute_reply.started":"2025-11-14T22:09:24.653806Z","shell.execute_reply":"2025-11-14T22:09:25.475971Z"}},"outputs":[{"name":"stdout","text":"Instruction: what is an Artificial Neural Network?\nResponse: The neural network is designed for the following task. You need to process data, use the inputs, and make predictions. This is done by creating a neural network architecture that is able to perform the task. Once the input is properly trained, you can use it for a variety of tasks.  The neural network architecture is able to learn the patterns and behaviors of the data. The results of the neural network architecture are based on a combination of input, output, and output variables.\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\ntrainer.save_model(\"./QNA_pocketGPT_27M\")\ntokenizer.save_pretrained(\"./QNA_pocketGPT_27M\")\n\nshutil.make_archive(\"QNA_pocketGPT_27M\", \"zip\", \"./QNA_pocketGPT_27M\")\n\nFileLink(\"QNA_pocketGPT_27M.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T21:51:52.315191Z","iopub.execute_input":"2025-11-14T21:51:52.315855Z","iopub.status.idle":"2025-11-14T21:52:49.267980Z","shell.execute_reply.started":"2025-11-14T21:51:52.315828Z","shell.execute_reply":"2025-11-14T21:52:49.267317Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/QNA_pocketGPT_27M.zip","text/html":"<a href='QNA_pocketGPT_27M.zip' target='_blank'>QNA_pocketGPT_27M.zip</a><br>"},"metadata":{}}],"execution_count":60}]}